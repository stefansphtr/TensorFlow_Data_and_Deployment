{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-2-public/blob/adding_C4/C4/W1/assignment/C4_W1_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXdEnmVvXdUa"
      },
      "source": [
        "# Train Your Own Model and Serve It With TensorFlow Serving\n",
        "\n",
        "In this notebook, you will train a neural network to classify images of handwritten digits from the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. You will then save the trained model, and serve it using [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSfb9Qd5XdFL"
      },
      "source": [
        "**Warning: This notebook is designed to be run in a Google Colab only**.  It installs packages on the system and requires root access. If you want to run it in a local Jupyter notebook, please proceed with caution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Q8bkjeYTl-"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8r89tTPI-Kb"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XGFJmWjrKttn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "â€¢ Using TensorFlow Version: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq-214o8SNt0"
      },
      "source": [
        "## Import the MNIST Dataset\n",
        "\n",
        "The [MNIST](http://yann.lecun.com/exdb/mnist/) dataset contains 70,000 grayscale images of the digits 0 through 9. The images show individual digits at a low resolution (28 by 28 pixels). \n",
        "\n",
        "Even though these are really images, we will load them as NumPy arrays and not as binary image objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7MqDQO0KCaWS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 12s 1us/step\n"
          ]
        }
      ],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AIT-qX0QzLo-"
      },
      "outputs": [],
      "source": [
        "# EXERCISE: Scale the values of the arrays below to be between 0.0 and 1.0.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIDGu-EEzdKb"
      },
      "source": [
        "In the cell below use the `.reshape` method to resize the arrays to the following sizes:\n",
        "\n",
        "```python\n",
        "train_images.shape: (60000, 28, 28, 1)\n",
        "test_images.shape: (10000, 28, 28, 1)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XsIxeG6BzN4t"
      },
      "outputs": [],
      "source": [
        "# EXERCISE: Reshape the arrays below.\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aUw8ZxigB1Nx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "train_images.shape: (60000, 28, 28, 1), of float64\n",
            "test_images.shape: (10000, 28, 28, 1), of float64\n"
          ]
        }
      ],
      "source": [
        "print('\\ntrain_images.shape: {}, of {}'.format(train_images.shape, train_images.dtype))\n",
        "print('test_images.shape: {}, of {}'.format(test_images.shape, test_images.dtype))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcR0OKbOSj0c"
      },
      "source": [
        "## Look at a Sample Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VQMs4v_oSo9v"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "idx = 42\n",
        "\n",
        "plt.imshow(test_images[idx].reshape(28,28), cmap=plt.cm.binary)\n",
        "plt.title('True Label: {}'.format(test_labels[idx]), fontdict={'size': 16})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn_-9OsPYnDp"
      },
      "source": [
        "## Build a Model\n",
        "\n",
        "In the cell below build a `tf.keras.Sequential` model that can be used to classify the images of the MNIST dataset. Feel free to use the simplest possible CNN. Make sure your model has the correct `input_shape` and the correct number of output units."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EgMgJJynMbVY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 8)         80        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 8)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 32)        2336      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 800)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               205056    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 210042 (820.48 KB)\n",
            "Trainable params: 210042 (820.48 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# EXERCISE: Create a model.\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLzXnZT1YvS6"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "In the cell below configure your model for training using the `adam` optimizer, `sparse_categorical_crossentropy` as the loss, and `accuracy` for your metrics. Then train the model for the given number of epochs, using the `train_images` array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LTNN0ANGgA36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "1875/1875 - 15s - loss: 0.1487 - accuracy: 0.9550 - 15s/epoch - 8ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 13s - loss: 0.0501 - accuracy: 0.9848 - 13s/epoch - 7ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 12s - loss: 0.0336 - accuracy: 0.9894 - 12s/epoch - 7ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 13s - loss: 0.0242 - accuracy: 0.9922 - 13s/epoch - 7ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 14s - loss: 0.0193 - accuracy: 0.9937 - 14s/epoch - 7ms/step\n"
          ]
        }
      ],
      "source": [
        "# EXERCISE: Configure the model for training.\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "# EXERCISE: Train the model.\n",
        "history = model.fit(train_images, train_labels, epochs=epochs, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er_vrDhf4qu5"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gMD387B93f2g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 0.0316\n",
            "accuracy: 0.991\n"
          ]
        }
      ],
      "source": [
        "# EXERCISE: Evaluate the model on the test images.\n",
        "results_eval = model.evaluate(test_images, test_labels, verbose=0)\n",
        "\n",
        "for metric, value in zip(model.metrics_names, results_eval):\n",
        "    print(metric + ': {:.3}'.format(value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGfmT8M1Yx5y"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9uFDoDW_7HX6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\lenovo\\AppData\\Local\\Temp\\1\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\lenovo\\AppData\\Local\\Temp\\1\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "export_path = C:\\Users\\lenovo\\AppData\\Local\\Temp\\1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "MODEL_DIR = tempfile.gettempdir()\n",
        "\n",
        "version = 1\n",
        "\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "\n",
        "if os.path.isdir(export_path):\n",
        "    print('\\nAlready saved a model, cleaning up\\n')\n",
        "    !rm -r {export_path}\n",
        "\n",
        "model.save(export_path, save_format=\"tf\")\n",
        "\n",
        "print('\\nexport_path = {}'.format(export_path))\n",
        "!ls -l {export_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KziE3e9tY-hH"
      },
      "source": [
        "## Examine Your Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LU4GDF_aYtfQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['input_1'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28, 1)\n",
            "        name: serving_default_input_1:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_1'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "The MetaGraph with tag set ['serve'] contains the following ops: {'MergeV2Checkpoints', 'BiasAdd', 'Pack', 'MaxPool', 'Reshape', 'Identity', 'Select', 'Conv2D', 'ShardedFilename', 'SaveV2', 'VarHandleOp', 'Const', 'StaticRegexFullMatch', 'StatefulPartitionedCall', 'Softmax', 'Relu', 'StringJoin', 'RestoreV2', 'DisableCopyOnRead', 'ReadVariableOp', 'NoOp', 'MatMul', 'AssignVariableOp', 'Placeholder'}\n",
            "\n",
            "Concrete Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsDTdBGHZAzo"
      },
      "source": [
        "## Add TensorFlow Serving Distribution URI as a Package Source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWg9X2QHlbGS"
      },
      "outputs": [],
      "source": [
        "# This is the same as you would do from your command line, but without the [arch=amd64], and no sudo\n",
        "# You would instead do:\n",
        "# echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "# curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
        "\n",
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l5XkzqNZNBU"
      },
      "source": [
        "## Install TensorFlow Serving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygwa9AgRloYy"
      },
      "outputs": [],
      "source": [
        "!apt-get install tensorflow-model-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd_PobAKZWW8"
      },
      "source": [
        "## Run the TensorFlow Model Server\n",
        "\n",
        "You will now launch the TensorFlow model server with a bash script. In the cell below use the following parameters when running the TensorFlow model server:\n",
        "\n",
        "* `rest_api_port`: Use port `8501` for your requests.\n",
        "\n",
        "\n",
        "* `model_name`: Use `digits_model` as your model name. \n",
        "\n",
        "\n",
        "* `model_base_path`: Use the environment variable `MODEL_DIR` defined below as the base path to the saved model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUgp3vUdU5GS"
      },
      "outputs": [],
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJDhHNJVnaLN"
      },
      "outputs": [],
      "source": [
        "# EXERCISE: Fill in the missing code below.\n",
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port= 8501 \\\n",
        "  --model_name= mnist_model \\\n",
        "  --model_base_path= \"${MODEL_DIR}\" >server.log 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxbeiOCUUs2z"
      },
      "outputs": [],
      "source": [
        "!tail server.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mUrIWVRZdNu"
      },
      "source": [
        "## Create JSON Object with Test Images\n",
        "\n",
        "In the cell below construct a JSON object and use the first three images of the testing set (`test_images`) as your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dsD7KQG1m-R"
      },
      "outputs": [],
      "source": [
        "# EXERCISE: Create JSON Object\n",
        "data = json.dumps(\n",
        "    {\"signature_name\": \"serving_default\",\n",
        "     \"instances\": test_images[0:3].tolist()}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRdyPl4CZ5CU"
      },
      "source": [
        "## Make Inference Request\n",
        "\n",
        "In the cell below, send a predict request as a POST to the server's REST endpoint, and pass it your test data. You should ask the server to give you the latest version of your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGvFyuIzW6n6"
      },
      "outputs": [],
      "source": [
        "# EXERCISE: Fill in the code below\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "\n",
        "url = \"http://localhost:8501/v1/models/mnist_model:predict\"\n",
        "\n",
        "json_response = requests.post(\n",
        "    url,\n",
        "    data=data,\n",
        "    headers=headers\n",
        ")\n",
        "    \n",
        "predictions = json.loads(json_response.text)['predictions']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtrFMts_ackX"
      },
      "source": [
        "## Plot Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxQzj34aiDz1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,15))\n",
        "\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(test_images[i].reshape(28,28), cmap = plt.cm.binary)\n",
        "    plt.axis('off')\n",
        "    color = 'green' if np.argmax(predictions[i]) == test_labels[i] else 'red'\n",
        "    plt.title('Prediction: {}\\nTrue Label: {}'.format(np.argmax(predictions[i]), test_labels[i]), color=color)\n",
        "    \n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "C4_W1_Assignment.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
