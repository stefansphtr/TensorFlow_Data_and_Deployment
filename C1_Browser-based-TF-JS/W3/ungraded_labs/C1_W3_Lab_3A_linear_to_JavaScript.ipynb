{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zX4Kg8DUTKWO"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 992
    },
    "colab_type": "code",
    "id": "pLTlDFwU1Ux_",
    "outputId": "35a170f8-c16f-48b5-a68a-d456338467eb"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 18235
    },
    "colab_type": "code",
    "id": "vNHv1d2K0Wxg",
    "outputId": "109c8bc7-6d51-4f0a-d3a6-f2943221ff49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lenovo\\.virtualenvs\\ungraded_labs-W3o6yLqY\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "â€¢ Using TensorFlow Version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print('\\u2022 Using TensorFlow Version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lenovo\\.virtualenvs\\ungraded_labs-W3o6yLqY\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\lenovo\\.virtualenvs\\ungraded_labs-W3o6yLqY\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:From c:\\Users\\lenovo\\.virtualenvs\\ungraded_labs-W3o6yLqY\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 11.0408\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9037\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2178\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8871\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8358\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.0046\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3465\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8247\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4102\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0803\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8169\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6060\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4365\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2995\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1883\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0974\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0225\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9604\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9083\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8641\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8263\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7936\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7649\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7394\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7165\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6958\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6767\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6591\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6426\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6271\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6124\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5984\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5850\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5721\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5596\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5476\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5359\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5245\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5135\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5027\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4922\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4820\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4720\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4622\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4527\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4433\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4342\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4252\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4165\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4079\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3995\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3913\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3832\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3754\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3676\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3601\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3527\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3454\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3383\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3314\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3246\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3179\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3114\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3050\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2987\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2926\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2866\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2807\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2749\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2693\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2637\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2583\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2530\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2478\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2427\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2377\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2329\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2281\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2234\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2188\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2143\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2099\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2056\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2014\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1972\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1932\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1892\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1853\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1815\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1778\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1741\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1706\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1671\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1636\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1603\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1570\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1538\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1506\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1475\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1445\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1415\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1386\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1358\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1330\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1302\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1276\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1249\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1224\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1199\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1174\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 363us/step - loss: 0.1150\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1126\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1103\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1080\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1058\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1036\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1015\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0994\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0974\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0954\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0934\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0915\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0896\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0878\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0860\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0842\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0825\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0808\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0791\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0775\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0759\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0744\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0728\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0713\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0699\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0684\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0670\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0657\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0643\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0630\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0617\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0604\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0592\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0580\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0568\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0556\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0545\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0533\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0523\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0512\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0501\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0491\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0481\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0471\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0461\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0452\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0443\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0434\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0425\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0416\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0407\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0399\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0391\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0383\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0375\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0367\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0360\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0352\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0345\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0338\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0331\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0324\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0318\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0311\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0305\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0298\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0292\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0286\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0280\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0275\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0269\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0263\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0258\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0253\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0248\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0242\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0237\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0233\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0228\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0223\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0219\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0214\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0210\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0205\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0201\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0193\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0189\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0185\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0181\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0178\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0174\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0167\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0160\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0157\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0154\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0150\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0147\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0144\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0141\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0138\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0136\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0133\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0130\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0127\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0125\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0122\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0120\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0117\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0115\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0112\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0110\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0108\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0106\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0104\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0101\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0099\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0097\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0095\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0093\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0091\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0090\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0088\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0086\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0084\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0082\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0081\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0079\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0077\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0076\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0074\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0073\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0071\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0070\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0068\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0067\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0066\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0064\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0063\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0062\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0060\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0059\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0058\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0057\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0056\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0054\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0052\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0051\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0049\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0048\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0047\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0046\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0045\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 914us/step - loss: 0.0044\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0043\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0042\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0042\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0041\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0040\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0039\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0038\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0037\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0037\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0036\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0035\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0034\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0034\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0032\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0032\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0031\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0030\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0030\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0029\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0029\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0028\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0027\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0026\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0025\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0025\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0024\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0024\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0023\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0023\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0022\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0022\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0021\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0021\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0021\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0020\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0019\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0018\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0018\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0018\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0017\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0017\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0017\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0016\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0016\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0016\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0015\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0013\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0013\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0013\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0012\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0011\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0011\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 509us/step - loss: 0.0011\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0011\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0011\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0010\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0010\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 9.9203e-04\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7165e-04\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5170e-04\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.3215e-04\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.1300e-04\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.9425e-04\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.7588e-04\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.5788e-04\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4026e-04\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.2300e-04\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.0610e-04\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.8954e-04\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.7332e-04\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.5744e-04\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.4188e-04\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2664e-04\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1171e-04\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9710e-04\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.8278e-04\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.6876e-04\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.5502e-04\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4156e-04\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2839e-04\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.1548e-04\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0284e-04\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.9046e-04\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7833e-04\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.6644e-04\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.5481e-04\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.4341e-04\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.3225e-04\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.2132e-04\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.1061e-04\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.0012e-04\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.8985e-04\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.7979e-04\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.6993e-04\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6028e-04\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.5083e-04\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.4156e-04\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3249e-04\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.2361e-04\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1491e-04\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0639e-04\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9804e-04\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8986e-04\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8186e-04\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7401e-04\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6633e-04\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5881e-04\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.5144e-04\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.4422e-04\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.3715e-04\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.3022e-04\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2344e-04\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1680e-04\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1029e-04\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.0392e-04\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.9768e-04\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.9156e-04\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.8557e-04\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.7971e-04\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.7396e-04\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.6834e-04\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6282e-04\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.5742e-04\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.5214e-04\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4696e-04\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.4189e-04\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3692e-04\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.3205e-04\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.2728e-04\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2262e-04\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.1804e-04\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.1356e-04\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0918e-04\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0488e-04\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.0067e-04\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9655e-04\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.9251e-04\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8856e-04\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.8469e-04\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8089e-04\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7718e-04\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.7354e-04\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6997e-04\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6648e-04\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6306e-04\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5971e-04\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5643e-04\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5322e-04\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5007e-04\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4699e-04\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4397e-04\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4101e-04\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3811e-04\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3528e-04\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3250e-04\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2978e-04\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2711e-04\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2450e-04\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2194e-04\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1944e-04\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1698e-04\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1458e-04\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1223e-04\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0992e-04\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0766e-04\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0545e-04\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0329e-04\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0116e-04\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.9086e-05\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.7050e-05\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 9.5058e-05\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.3105e-05\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.1192e-05\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.9320e-05\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.7485e-05\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.5687e-05\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3928e-05\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.2204e-05\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.0515e-05\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.8861e-05\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7242e-05\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5655e-05\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.4100e-05\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2580e-05\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1087e-05\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9629e-05\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8198e-05\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.6797e-05\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5425e-05\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4082e-05\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.2766e-05\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.1475e-05\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0213e-05\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.8976e-05\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.7765e-05\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.6578e-05\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.5417e-05\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.4278e-05\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.3163e-05\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2070e-05\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1001e-05\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.9954e-05\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.8927e-05\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.7922e-05\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.6937e-05\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5973e-05\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.5029e-05\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.4104e-05\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.3198e-05\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.2310e-05\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.1442e-05\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.0591e-05\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9757e-05\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8940e-05\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8139e-05\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7356e-05\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6589e-05\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.5837e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20a18da7cd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(units=1, input_shape=[1])  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
    "\n",
    "model.fit(xs, ys, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AxSZ4DzJGEKy",
    "outputId": "00023ac5-58cb-4e09-9ac0-9ae8ae59f846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "[[18.982536]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([10.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\.virtualenvs\\ungraded_labs-W3o6yLqY\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "saved_model_path = \"./{}.h5\".format(int(time.time()))\n",
    "\n",
    "model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 11:47:19.101278: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:root:TensorFlow Decision Forests 1.8.1 is compatible with the following TensorFlow Versions: ['2.15.0']. However, TensorFlow 2.15.1 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n",
      "WARNING:root:Failure to load the inference.so custom c++ tensorflow ops. This error is likely caused the version of TensorFlow and TensorFlow Decision Forests are not compatible. Full error:C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\tensorflowjs_converter.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs import converters\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\converters\\__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs.converters.converter import convert\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 38, in <module>\n",
      "    from tensorflowjs.converters import tf_saved_model_conversion_v2\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\converters\\tf_saved_model_conversion_v2.py\", line 28, in <module>\n",
      "    import tensorflow_decision_forests\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\__init__.py\", line 64, in <module>\n",
      "    from tensorflow_decision_forests import keras\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\keras\\__init__.py\", line 53, in <module>\n",
      "    from tensorflow_decision_forests.keras import core\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\keras\\core.py\", line 62, in <module>\n",
      "    from tensorflow_decision_forests.keras import core_inference\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\keras\\core_inference.py\", line 36, in <module>\n",
      "    from tensorflow_decision_forests.tensorflow.ops.inference import api as tf_op\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\api.py\", line 179, in <module>\n",
      "    from tensorflow_decision_forests.tensorflow.ops.inference import op\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op.py\", line 15, in <module>\n",
      "    from tensorflow_decision_forests.tensorflow.ops.inference.op_dynamic import *\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op_dynamic.py\", line 24, in <module>\n",
      "    raise e\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op_dynamic.py\", line 21, in <module>\n",
      "    ops = tf.load_op_library(resource_loader.get_path_to_datafile(\"inference.so\"))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\load_library.py\", line 54, in load_op_library\n",
      "    lib_handle = py_tf.TF_LoadLibrary(library_filename)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found\n"
     ]
    }
   ],
   "source": [
    "!tensorflowjs_converter --input_format=keras {saved_model_path} ./"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Linear-to-JavaScript.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
